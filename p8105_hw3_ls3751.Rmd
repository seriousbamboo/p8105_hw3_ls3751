---
title: "p8105_hw3_ls3751"
author: "Liucheng Shi"
output: github_document
---

_packages required_
```{r setup, message = F}
library(tidyverse)
library(p8105.datasets)
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and ... columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```


Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


Apples vs ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```

### Problem 2

#### 1.1 load the dataset and tidy data

```{r, message = F, warning = F}
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440, 
    names_to = "minute",
    names_prefix = "activity_", 
    values_to = "counts"
  )
```

#### 1.2 Create a variable that indicate the weekday/weekend status and modify variable formats

```{r}
accel_df = accel_df %>% 
  mutate(
    weekday_weekend = case_when(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      day %in% c("Saturday", "Sunday") ~ "weekend",
      TRUE ~ "")
      ) %>% 
  mutate(
    minute = as.numeric(minute),
    week = factor(week),
    day = forcats::fct_relevel(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")
    )) %>% 
  relocate(weekday_weekend, .before = minute)
```

#### 1.3 Overview

After data cleaning and wrangling, this dataset has `r nrow(accel_df)` observations with `r ncol(accel_df)` variables, including `r names(accel_df)`.  

*   _week_id_: the week indicator ranging from 1 to 5.
*   _day_id_: the day indicator ranging from 1 to 35 (5 weeks in total).
*   _day_ & _weekday_weekend_: ex: Sunday, weekend. 
*   _minutes_: the recorded time  (1440 min a day). 
*   _counts_: the count of activities measured by accelerometer. 

#### 2. Traditional analyses of accelerometer

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarise(activity_sum = sum(counts, na.rm = T)) %>% 
  pivot_wider(
   names_from = week,
   names_prefix = "week",
   values_from = activity_sum
  ) %>% 
  knitr::kable(digits = 1)
```

Besides the extreme large activity counts on Sunday Week 1 and two extreme small counts on Saturdays Week 4 and 5, this table is not easy to interpret and there is no apparent trend detected.

Ranking with the sum of activity counts.

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarise(activity_sum = sum(counts, na.rm = T)) %>% 
  mutate(rank = min_rank(desc(activity_sum))) %>% 
  select(-activity_sum) %>% 
  pivot_wider(
   names_from = week,
   names_prefix = "week",
   values_from = rank
  ) %>% 
  knitr::kable()
```

The table using ranks within the week is not easy to read neither.

#### 3. Make a single-panel plot that shows the 24-hour activity time courses for each day

```{r}
accel_df %>% 
  group_by(week,day) %>%
  mutate(hour = floor((minute-1)/60)) %>%
  ungroup() %>% 
  group_by(week,day,hour) %>% 
  summarise(activity_mean = mean(counts, na.rm = T)) %>% 
  ggplot(aes(x = hour, y = activity_mean)) +
  geom_point(aes(color = day), alpha = .5) +
  geom_smooth()
  
```


### Problem 3

#### 1. Overview

```{r, message = F}
library(lubridate)
data("ny_noaa")
range(pull(ny_noaa,date))
```

This dataset has `r nrow(ny_noaa)` observations collected from `r ny_noaa %>% summarize(n_distinct(id))` weather stations with `r ncol(ny_noaa)` variables.

*   _id_: the indicator of which site did the record.
*   _date_: the recorded dat from 1981.1.1 to 2010.12.31. 
*   _prcp_: the  precipitation in mm.
*   _snow_: snowfall in mm.
*   _snwd_: snow depth in mm.
*   _tmax_ and _tmin_: the maximum and minimum temperature recorded.


```{r}
ny_noaa %>% 
  summarise(tmax_na = (sum(is.na(tmax)))/nrow(ny_noaa),
            tmin_na = (sum(is.na(tmin)))/nrow(ny_noaa),
            prcp_na = (sum(is.na(prcp)))/nrow(ny_noaa),
            snow_na = (sum(is.na(snow)))/nrow(ny_noaa),
            snwd_na = (sum(is.na(snwd)))/nrow(ny_noaa))
```

The missing values on tmin and tmax seems to be problematic (over 40%) compared with other variables (less than 6%).

#### 2. Do some data cleaning. Create separate variables for year, month, and day. Ensure observations for temperature, precipitation, and snowfall are given in reasonable units.

```{r}
ny_df <- ny_noaa %>% 
  mutate(year = year(date),
         month = month(date), 
         day = day(date)) %>%
  mutate(tmax = as.numeric(tmax)/10,
         tmin = as.numeric(tmin)/10,
         prcp = as.numeric(prcp)/10)
ny_df %>% 
  count(snow) %>% 
  arrange(desc(n))
```

The most common observed value for snowfall is 0 since we do not expect to have any snowfall during a long period of every year.

#### 3. Make a two-panel plot showing the average max temperature in January and in July in each station across years.

```{r, message = F}
ny_jan_jul = ny_df %>% 
  filter(month %in% c(1, 7)) %>% 
  group_by(id, year, month) %>% 
  summarize(avg_tmax = mean(tmax, na.rm = TRUE)) %>% 
  drop_na()
 
ny_jan_jul %>% 
  ggplot(aes(x = year, y = avg_tmax, color = id)) +
  geom_point(alpha = .5) +
  geom_path(alpha = .3) +
  labs(
    title = "Average max temperature in January and July",
    subtitle = "1981-2010, New York state",
    x = "Time (year)",
    y = "Average max temperature (C)",
    caption = "From NOAA") +
  scale_x_continuous(breaks = c(seq(1980,2010, by = 5)),
                   labels = c(seq(1980,2010, by = 5))) +
  facet_grid(.~month) +
  theme(legend.position = "none", axis.text.x = element_text(angle = 270,  vjust = 0.5,  hjust = 1))
```

The average max temperature in January distributed from -10 C to 10 C with few outliers(e.g.1982, 1994, 2005). It seems to be centered at 0 C.  
The average max temperature in July has a smaller variation compared with January, ranging from 20 C to 35 C. It seems to be centered at 27.5 C. A few more outliers were detected (1984, 1988, 2004, 2007).

#### 4. Make a two-panel plot

##### 4.1 showing tmax vs tmin for the full dataset

```{r}
tmax_tmin = ny_df %>% 
  drop_na(tmax,tmin) %>% 
  ggplot(aes(x = tmax, y = tmin)) +
  geom_hex() +
  labs(
    title = "Maximum temp vs. minimum ",
    subtitle = "1981-2010 New York state",
    x = "Max temperature (C)",
    y = "Min temperature (C)",
    caption = "From NOAA") +
  theme(legend.text = element_text(size = 5))
```


##### 4.2 make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year

```{r}
snow_plot = ny_df %>%
  select(year, snow) %>% 
  filter(snow > 0 & snow < 100) %>% 
  mutate(year = factor(year)) %>% 
  ggplot(aes(x = snow, y = year)) + 
  geom_density_ridges(color = "red", fill = "green") + 
  labs(
    title = "Distribution of snowfall by year",
    subtitle = "1981-2010 New York state",
    x = "Snowfall (mm)",
    y = "Year") 
```

##### 4.3 show two plots using patchwork

```{r, fig.width = 16, fig.height = 10}
tmax_tmin + snow_plot
```

