---
title: "p8105_hw3_ls3751"
author: "Liucheng Shi"
output: github_document
---

_packages required_
```{r setup, message = F}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and ... columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```


Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


Apples vs ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```

### Problem 2

#### 1.1 load the dataset and tidy data

```{r, message = F, warning = F}
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440, 
    names_to = "minute",
    names_prefix = "activity_", 
    values_to = "counts"
  )
```

#### 1.2 Create a variable that indicate the weekday/weekend status and modify variable formats

```{r}
accel_df = accel_df %>% 
  mutate(
    weekday_weekend = case_when(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      day %in% c("Saturday", "Sunday") ~ "weekend",
      TRUE ~ "")
      ) %>% 
  mutate(
    minute = as.numeric(minute),
    week = factor(week),
    day = forcats::fct_relevel(day, c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")
    )) %>% 
  relocate(weekday_weekend, .before = minute)
```

#### 1.3 Overview

After data cleaning and wrangling, this dataset has `r nrow(accel_df)` observations with `r ncol(accel_df)` variables, including `r names(accel_df)`.  

*   _week_id_: the week indicator ranging from 1 to 5.
*   _day_id_: the day indicator ranging from 1 to 35 (5 weeks in total).
*   _day_ & _weekday_weekend_: ex: Sunday, weekend. 
*   _minutes_: the recorded time  (1440 min a day). 
*   _counts_: the count of activities measured by accelerometer. 

#### 2. Traditional analyses of accelerometer

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarise(activity_sum = sum(counts, na.rm = T)) %>% 
  pivot_wider(
   names_from = week,
   names_prefix = "week",
   values_from = activity_sum
  ) %>% 
  knitr::kable(digits = 1)
```

Besides the extreme large activity counts on Sunday Week 1 and two extreme small counts on Saturdays Week 4 and 5, this table is not easy to interpret and there is no apparent trend detected.

Ranking with the sum of activity counts.

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarise(activity_sum = sum(counts, na.rm = T)) %>% 
  mutate(rank = min_rank(desc(activity_sum))) %>% 
  select(-activity_sum) %>% 
  pivot_wider(
   names_from = week,
   names_prefix = "week",
   values_from = rank
  ) %>% 
  knitr::kable()
```

The table using ranks within the week is not easy to read neither.

#### 3. Make a single-panel plot that shows the 24-hour activity time courses for each day

```{r}
accel_df %>% 
  group_by(week,day) %>%
  mutate(hour = floor((minute-1)/60)) %>%
  ungroup() %>% 
  group_by(week,day,hour) %>% 
  summarise(activity_mean = mean(counts, na.rm = T)) %>% 
  ggplot(aes(x = hour, y = activity_mean)) +
  geom_point(aes(color = day), alpha = .5)
  
```


### Problem 3

#### 1. Overview

```{r, message = F}
library(lubridate)
data("ny_noaa")
range(pull(ny_noaa,date))
```

This dataset has `r nrow(ny_noaa)` observations collected from `r ny_noaa %>% summarize(n_distinct(id))` weather stations with `r ncol(ny_noaa)` variables.

*   _id_: the indicator of which site did the record.
*   _date_: the recorded dat from 1981.1.1 to 2010.12.31. 
*   _prcp_: the  precipitation in mm.
*   _snow_: snowfall in mm.
*   _snwd_: snow depth in mm.
*   _tmax_ and _tmin_: the maximum and minimum temperature recorded.


```{r}
ny_noaa %>% 
  summarise(tmax_na = (sum(is.na(tmax)))/nrow(ny_noaa),
            tmin_na = (sum(is.na(tmin)))/nrow(ny_noaa),
            prcp_na = (sum(is.na(prcp)))/nrow(ny_noaa),
            snow_na = (sum(is.na(snow)))/nrow(ny_noaa),
            snwd_na = (sum(is.na(snwd)))/nrow(ny_noaa))
```

The missing values on tmin and tmax seems to be problematic (over 40%) compared with other variables (less than 6%).

#### 2. Do some data cleaning. Create separate variables for year, month, and day. Ensure observations for temperature, precipitation, and snowfall are given in reasonable units.

```{r}
ny_df <- ny_noaa %>% 
  mutate(year = year(date),
         month = month(date), 
         day = day(date)) %>%
  mutate(tmax = as.numeric(tmax)/10,
         tmin = as.numeric(tmin)/10,
         prcp = as.numeric(prcp)/10)
ny_df %>% 
  count(snow) %>% 
  arrange(desc(n))
```

The most common observed value for snowfall is 0 since we do not expect to have any snowfall during a long period of every year.

#### 3. Make a two-panel plot showing the average max temperature in January and in July in each station across years.

```{r}

```

